---
title: "Probability theory: The logic of science"
author: "Edoardo Marcora"
date: 2023-08-02
---

## Why study probability?

-   **Probability** is the basis for **inductive reasoning** (i.e., reasoning with probabilities).
-   **Scientific reasoning** is inductive reasoning (e.g., generalization, prediction, causal inference, etc.).
-   Unfortunately, humans suffer from "probability blindness" and are often incorrect when reasoning with probabilities.
-   **Probability theory** is the study of probability as a mathematical object.
-   Probability theory is the foundation of **statistical inference** (i.e., learning from data under uncertainty), a cornerstone of modern data analysis and scientific research.

## Logic: Inductive vs. deductive reasoning

-   **Logic** is the study of **correct reasoning**.
-   Reasoning is the process of drawing a conclusion from one or more premises.
-   Reasoning is put into words in the form of an argument.
-   An **argument** is a set of statements; more specifically **one or more premises and a conclusion**.

$$
\begin{align}
& \text{premise}_1 \\
& \text{premise}_2 \\
& \ldots \\
& \text{premise}_n \\
& \overline{\therefore \text{conclusion}}
\end{align}
$$

-   A statement is a sentence that asserts a proposition/claim that is either true or false based on its correspondence with reality/the state of affairs in the world.
-   In an argument, the premises are the evidence given in support of the conclusion. The conclusion is the statement/proposition that the argument seeks to prove as definitely true (**deductive argument**) or likely true (**inductive argument**) if the premises are true.

[![](/images/reasoning_flowchart.png)](https://youtu.be/6Sg9zI-GNsI)

-   A **valid deductive argument** guarantees a definitely true conclusion if the premises are true, i.e., in valid deductive argument the premises fully entail the conclusion. When the premises are true and the deductive argument is valid, it is also **sound**.
-   A **strong inductive argument** guarantees a likely true conclusion if the premises are true, i.e., in a strong inductive argument the premises partially entail the conclusion. When the premises are true and the inductive argument is strong, it is also **cogent**.
-   How likely is the conclusion given the premises? Probability theory can help us find the answer!
-   How likely does the conclusion need to be before it's rational to accept it? Decision theory (e.g., cost-benefit analysis) can help us find the answer!

## Logical operators and truth tables

-   Statements/propositions can be combined using logical operators:
    -   AND
    -   OR
    -   NOT
-   Truth tables:
    -   XXX

## Probability: Proposition vs. event language

Two ways of asking the same question:

1.  *"What is the probability that the coin will land heads?"*
    -   **Proposition**: *"the coin will land heads"*
    -   **Question**: What is the probability that this **proposition** is **true**?
    -   A proposition is a claim that is either true or false based on its correspondence with reality/the state of affairs in the world.
    -   Better fit for the logical or bayesian/"subjective" interpretations of probability.
2.  *"What is the probability of the coin landing heads?"*
    -   **Event**: *"the coin landing heads"*
    -   **Question**: What is the probability that this **event** will **occur**?
    -   An event is a state of affairs in the world that either occurs or doesn't occur.
    -   Better fit for the classical or frequentist/"objective" interpretations of probability.

## Set theory

-   A **set** is a collection of objects, typically referred to as **elements** (or members) of the set.
-   The objects within a set can be anything---numbers, letters, people, animals, sets, or any other entities---as long as they are well-defined and distinct, e.g.:
    -   $\{1, 3, 5, 7\}$
    -   **natural numbers**: $\mathbb{N} = \{1,2,3,\ldots \}\quad \text{or} \quad \{0, 1,2,3,\ldots \}$
    -   **integers**: $\mathbb{Z} = \{ \ldots, -3, -2, -1, 0, 1, 2, 3, \ldots \}$
    -   **real numbers**: $\mathbb{R}$
    -   $\{ a, b, c, d \}$
    -   $\{ \{1, 3, 5, 7 \} , \{ a, b, c, d \} \}$
    -   $\{ ⚀, ⚁, ⚂, ⚃, ⚄, ⚅ \}$
    -   $\{ ⚀⚀, ⚀⚁, ⚀⚂, ⚀⚃, ⚀⚄, ⚀⚅, ⚁⚀, ⚁⚁, ⚁⚂, ⚁⚃, ⚁⚄, ⚁⚅, ⚂⚀, ⚂⚁, ⚂⚂, ⚂⚃, ⚂⚄, ⚂⚅, ⚃⚀, ⚃⚁, ⚃⚂, ⚃⚃, ⚃⚄, ⚃⚅, ⚄⚀, ⚄⚁, ⚄⚂, ⚄⚃, ⚄⚄, ⚄⚅, ⚅⚀, ⚅⚁, ⚅⚂, ⚅⚃, ⚅⚄, ⚅⚅ \}$
    -   $\{ 🐱, 🐶, 🐰, 🐭, 🐻, 🐷, 🐴, 🐤, 🐵, 🐟, 🦖, 🐸, 🦑, 🦀, 🐞, 👽, 🎅 \}$
    -   $\{ 🟥, 🟩, 🟦, 🔴, 🟢, 🔵 \}$
-   Sets can be combined using set operators:
    -   $A = \{ x : x \in A \}$
    -   $B = \{ x : x \in B \}$
    -   Union: $A \cup B = \{ x : x \in A \lor x \in B \}$
    -   Intersection: $A \cap B = \{ x : x \in A \land x \in B \}$
    -   Complement: $A^\complement = \{ x : x \notin A \}$

## Probability as a mathematical object

Probability theory is the study of probability as a mathematical object.

Probability as a function that satisfies the axioms of probability.

In mathematics, a function is an assignment of an element $y$ of a set $Y$ to each element $x$ of a set $X$.

FUNCTION: $f: X \rightarrow Y$

INPUT: $x$

OUTPUT: $y = f(x)$

The **sample space** $\Omega$ is the set of all possible outcomes of a random phenomenon/stochastic process/"experiment", e.g., tossing a coin.

The power set of a set $S$ is the set of all subsets of $S$, including the empty set $\emptyset$ and $S$ itself.

The **event space** $F$ is the power set of the sample space $\Omega$.

An **event** $A$ is a subset of the sample space $\Omega$:

$A \subseteq \Omega$

and therefore an element of the event space $F$:

$A \in F$

**Probability** is a function $P$ from the event space $F$ to the real numbers $\mathbb{R}$:

$P : F \rightarrow \mathbb{R}$

$P(A)$ is the probability of event (or proposition) $A$, i.e., a real number.

A real number is a number that can be used to measure a continuous one-dimensional quantity such as a distance, duration, temperature.

$P(A)$ is a measure of uncertainty, i.e., the likelihood that event $A$ will occur or that proposition $A$ is true.

## The axioms of probability

Probability as a function $P : F \rightarrow \mathbb{R}$ must satisfy a number of axioms (Kolmogorov axioms; see also [Cox's theorem](https://en.wikipedia.org/wiki/Cox%27s_theorem) as an alternative):

-   $P(A) \ge 0 \quad \forall A \in F$
-   $P(\Omega) = 1$
-   $\text{if} \quad A_1, A_2, \ldots, A_n \ \text{are disjoint/mutually exclusive events} \quad \text{then} \quad P(\cup_{i=1}^n A_i) = \sum_{i=1}^n P(A_i)$

All rules of probability are derived from these axioms, for example:

$0 \le P(A) \le 1 \quad \forall A \in F$

$P(\emptyset) = 0$

$\text{if} \quad A \subseteq B \quad \text{then} \quad P(A) \le P(B)$

## Example: A single toin coss

Consider a single coin toss and assume that the coin will either land heads ($H$) or tails ($T$) (but not both):

$\Omega = \{H, T\}$

$F = \{ \emptyset, \{H\}, \{T\}, \{H,T\} \}$

If we assume that the coin is fair (i.e., it has equal probability of landing heads or tails):

$P(\emptyset) = 0$

$P(\{H,T\}) = P(\Omega) = 1$

$P(\{H,T\}) = P(\{H\}) + P(\{T\}) = 1$

$P(\{H\}) = P(\{T\}) = 0.5$

## Mutually exclusive/disjoint events

$P(A\ \text{and}\ B) = 0$

## Independent events

$P(A \mid B) = P(A)$

## The rules of probability

### Negation

$P(\text{not-}A) = 1 - P(A)$

Alternative notation for $P(\text{not-}A)$:

-   $P(A')$
-   $P(A^\complement)$
-   $P(\overline{A})$
-   $P(\lnot A)$

### Disjunction (sum/addition rule)

$P(A\ \text{or}\ B) = P(A) + P(B) - P(A\ \text{and}\ B)$

Alternative notation for $P(A\ \text{or}\ B)$:

-   $P(A \cup B)$

If $A$ and $B$ are mutually exclusive/disjoint events: $P(A \cup B) = P(A) + P(B)$

The disjunction rule is commutative: $P(A \cup B) = P(B \cup A)$

### Conjunction (product/multiplication rule)

$P(A\ \text{and} \ B) = P(A) \times P(B \mid A)$

Alternative notation for $P(A\ \text{and} \ B)$:

-   $P(AB)$
-   $P(A,B)$
-   $P(A \cap B)$

If $A$ and $B$ are independent events: $P(A \cap B) = P(A) \times P(B)$

The conjunction rule is commutative: $P(A \cap B) = P(B \cap A)$

## Conditional probability

$P(A \mid B) = \frac{P(A\ \text{and}\ B)}{P(B)}$

$P(A \mid B) \ne P(B \mid A)$

## Inverse probability: Bayes' theorem (or Bayes' rule)

$P(A\ \text{and} \ B) = P(A) \times P(B \mid A)$

$P(B\ \text{and} \ A) = P(B) \times P(A \mid B)$

$P(A\ \text{and}\ B) = P(B\ \text{and}\ A)$

$P(A) \times P(B \mid A) = P(B) \times P(A \mid B)$

$P(A \mid B) = \frac{P(A) \times P(B \mid A)}{P(B)}$

## Additional resources

-   Deductive and inductive reasoning flow chart \[[video](https://youtu.be/6Sg9zI-GNsI)\]
-   Basic concepts in logic and argumentation \[[videos](https://youtube.com/playlist?list=PLB8A5292FC68E2D77)\]
-   Reasoning with probabilities \[[videos](https://youtube.com/playlist?list=PL1D85E19690485A3E)\]
-   Introduction to probability \[[book](http://athenasc.com/probbook.html)\] \[[online course](https://www.edx.org/course/probability-the-science-of-uncertainty-and-data-0)\] \[[videos](https://youtube.com/playlist?list=PLUl4u3cNGP60hI9ATjSFgLZpbNJ7myAg6)\]
-   Bernoulli's fallacy \[[book](http://cup.columbia.edu/book/bernoullis-fallacy/9780231199957)\]
