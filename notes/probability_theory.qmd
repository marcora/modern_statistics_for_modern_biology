---
title: "Probability theory: The logic of science"
author: "Edoardo Marcora"
date: 2023-08-02
---

## Why study logic and probability?

-   **Probability** is an essential component of **inductive reasoning** (i.e., reasoning with probabilities), which plays a key role in **scientific reasoning**. Unfortunately, humans suck at inductive reasoning; we suffer from "probability blindness" and are often incorrect/illogical/fallacious when reasoning with probabilities.
-   **Probability theory** is the foundation of **statistical inference** (i.e., learning from data under uncertainty), the cornerstone of modern data analysis.

## Inductive vs. deductive reasoning

-   **Logic** is the study of **correct reasoning**.
-   Reasoning is the process of drawing a **conclusion** from a set of **premises**.
-   Reasoning is put into words in the form of an argument.
-   An **argument** is a set of statements/propositions; more specifically a set of premises and a conclusion.

$$
\begin{align}
& \text{premise}_1 \\
& \text{premise}_2 \\
& \ldots \\
& \text{premise}_n \\
& \overline{\therefore \text{conclusion}}
\end{align}
$$

-   A **statement/proposition** is a sentence that asserts a claim that is either true or false.
-   In an argument, the premises are the reasons or evidence given in support of the conclusion. The conclusion is the claim that the argument seeks to prove as definitely true (deductive argument) or likely true (inductive argument) assuming that the premises are true.
-   Conclusion indicator words: thus, ergo, hence, therefore, thus, consequently, it follows that, etc.
-   Premise indicator words: since, because, given that, follows from, assuming that, considering that, etc.
-   A deductive argument seeks to prove that the conclusion is definitely true assuming that the premises are true. In contrast, an inductive argument seeks to prove that the conclusion is likely true assuming that the premises are true.
-   Premises and conclusions are either true or false depending on whether they are in accord with reality.
-   A valid deductive argument ensures the conclusion is definitely true assuming that the premises are true. The conclusion follows with certainty from the premises, as the premises fully entail the conclusion.
-   A strong inductive argument ensures the conclusion is likely true assuming that the premises are true. The conclusion follows with high probability from the premises, as the premises partially entail the conclusion.
-   Probability can be understood as the measure of the degree to which a conclusion follows from the premises. It indicates the strength of the entailment between the premises and the conclusion.
-   How likely is the conclusion given the premises? Probability theory can help us find the answer!
-   How likely does the conclusion need to be before it's rational to accept it? Decision theory (e.g., cost-benefit analysis) can help us find the answer!
-   **Modus ponens**:

$$
\begin{align}
& A \rightarrow B \\
& A \\
& \overline{\therefore B}
\end{align}
$$

-   **Modus tollens**:

$$
\begin{aligned}
& A \rightarrow B \\
& \text{not-}A \\
& \overline{\therefore \text{not-}B}
\end{aligned}
$$

## Proposition vs. event language

Two ways of asking the same question!

*"What is the probability that the coin will land heads?"*

**Proposition**: *"the coin will land heads"*

**Question**: What is the probability that this **proposition** is **true**?

A proposition is a sentence that asserts a claim that is either true or false.

Better fit for the logical or bayesian/"subjective" interpretations of probability.

------------------------------------------------------------------------

*"What is the probability of the coin landing heads?"*

**Event**: *"the coin landing heads"*

**Question**: What is the probability that this **event** will **occur**?

An event in not a linguistic entity, it does not assert anything (that is either true or false). An event is a state of affairs in the world that either occurs or doesn't occur.

Better fit for the classical or frequentist/"objective" interpretations of probability.

## Probability as a mathematical object

In mathematics, a function is an assignment of an element $y$ of a set $Y$ to each element $x$ of a set $X$.

INPUT: $x$

FUNCTION: $f$

OUTPUT: $y = f(x)$

$f: X \rightarrow Y$

Probability is a function $P$ that assigns a number between 0 and 1 to each subset $A$ of a sample space $\Omega$ (i.e., the non-empty set of all possible outcomes of a random phenomemon/process/"experiment", e.g., tossing a coin).

$A$ is an event/proposition

$P(A)$ is the probability of $A$ (i.e., a number between 0 and 1)

$A \subseteq \Omega$

$E$ is an event space (i.e., the set of all possible subsets of a sample space $\Omega$)

$A \in E$

Probability (i.e., the function $P: E \rightarrow [0, 1]$) must satisfy a number of axioms (Kolmogorov axioms or Cox's theorem):

-   $P(A) \ge 0$
-   $P(\Omega) = 1$
-   $P$ is countably additive: if $A_1, A_2, \ldots, A_n$ are pairwise disjoint events, then $P(\cup_{i=1}^n A_i) = \sum_{i=1}^n P(A_i)$.

All rules of probability are derived from these axioms, for example:

$0 \le P(A) \le 1$

$P(\emptyset) = 0$

Probability theory is the study of probability as a mathematical object.

## Mutually exclusive/disjoint events

$P(A\ \text{and}\ B) = 0$

## Independent events

$P(A \mid B) = P(A)$

## The rules of probability

### Negation (NOT)

$P(\text{not-}A) = 1 - P(A)$

Alternative notation for $P(\text{not-}A)$:

-   $P(A')$
-   $P(A^\complement)$
-   $P(\overline{A})$
-   $P(\lnot A)$

### Disjunction (OR, sum/addition rule)

$P(A\ \text{or}\ B) = P(A) + P(B) - P(A\ \text{and}\ B)$

Alternative notation for $P(A\ \text{or}\ B)$:

-   $P(A \cup B)$

If $A$ and $B$ are mutually exclusive/disjoint events: $P(A \cup B) = P(A) + P(B)$

The disjunction rule is commutative: $P(A \cup B) = P(B \cup A)$

### Conjunction (AND, product/multiplication rule)

$P(A\ \text{and} \ B) = P(A) \times P(B \mid A)$

Alternative notation for $P(A\ \text{and} \ B)$:

-   $P(AB)$
-   $P(A,B)$
-   $P(A \cap B)$

If $A$ and $B$ are independent events: $P(A \cap B) = P(A) \times P(B)$

The conjunction rule is commutative: $P(A \cap B) = P(B \cap A)$

## Conditional probability

$P(A \mid B) = \frac{P(A\ \text{and}\ B)}{P(B)}$

$P(A \mid B) \ne P(B \mid A)$

## Inverse probability: Bayes' theorem (or Bayes' rule)

$P(A\ \text{and} \ B) = P(A) \times P(B \mid A)$

$P(B\ \text{and} \ A) = P(B) \times P(A \mid B)$

$P(A\ \text{and}\ B) = P(B\ \text{and}\ A)$

$P(A) \times P(B \mid A) = P(B) \times P(A \mid B)$

$P(A \mid B) = \frac{P(A) \times P(B \mid A)}{P(B)}$

## References

-   Logic: Fundamental Concepts \[[youtube playlist](https://youtube.com/playlist?list=PL6a98igNglIzgNAdPMpfOA71KVng49hwD)\]
-   Reasoning with Probabilities \[[youtube playlist](https://youtube.com/playlist?list=PL1D85E19690485A3E)\]
-   Introduction to Probability \[[book](http://athenasc.com/probbook.html)\] \[[online course](https://www.edx.org/course/probability-the-science-of-uncertainty-and-data-0)\] \[[youtube playlist](https://youtube.com/playlist?list=PLUl4u3cNGP60hI9ATjSFgLZpbNJ7myAg6)\]
-   Bernoulli's Fallacy \[[book](http://cup.columbia.edu/book/bernoullis-fallacy/9780231199957)\]
