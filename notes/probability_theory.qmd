---
title: "Probability theory: The logic of science"
author: "Edoardo Marcora"
date: 2023-08-02
---

## Why study probability?

-   **Probability** is an essential component of **inductive reasoning** (i.e., reasoning with probabilities) and inductive reasoning is at the core of **scientific reasoning**. Unfortunately, humans suck at inductive reasoning; we suffer from "probability blindness" and are often fallacious/illogical/incorrect when reasoning with probabilities.
-   **Probability theory** is the foundation of **statistical inference** (i.e., learning from data under uncertainty), the cornerstone of modern data analysis.

## Inductive vs. deductive reasoning

-   **Logic** is the study of correct **reasoning** (i.e., drawing correct inferences/conclusions from known or assumed facts/premises).
-   An **argument** is a set of propositions/claims; more specifically a set of **premises** together with a **conclusion**.

$$
\begin{align}
& \text{premise} \\
& \text{premise} \\
& \overline{\therefore \text{conclusion}}
\end{align}
$$

-   An **inference** is the process of reasoning from the premises of an argument to its conclusion.
-   A proposition is a sentence that asserts a claim that is either true or false (xor).
-   Inductive reasoning is distinct from deductive reasoning; the truth of the conclusion of a \[valid\] deductive argument is certain, if the premises are true; in contrast, the truth of the conclusion of a \[strong\] inductive argument is probable, if the premises are true.
-   Arguments/inferences are either correct or incorrect. If they are correct then their premises support their conclusion. If they are incorrect then their premises do not support their conclusion.
-   Premises and conclusions, on the other hand, are true or false depending on whether they are in accord with reality.
-   A deductive valid argument is one whose premises guarantee the truth of its conclusion. The conclusion follows with CERTAINTY from the premises. The premises entail the conclusion.
-   An inductive \[strong/weak\] argument is one whose premises do not guarantee the truth of its conclusion but only that its conclusion is true with some \[high/low\] probability. The conclusion follows NOT with CERTAINTY, but only with some \[high/low\] PROBABILITY, from the premises (a "risky" inference). The premises partially entail the conclusion (strong/weak logical support).
-   Probability as the degree of partial entailment (or logical support) of a conclusion, given the premises.
-   How strong is the inference? What is the probability of the conclusion, given the premises? Probability theory helps us answer this question!
-   How high does the probability/how strong does the inference have to be before it's rational/reasonable to accept the conclusion? Decision theory (e.g., cost-benefit analysis) helps us answer this question!
-   Modus ponens:

$$
\begin{align}
& A \rightarrow B \\
& A \\
& \overline{\therefore B}
\end{align}
$$

-   Modus tollens:

$$
\begin{aligned}
& A \rightarrow B \\
& \text{not-}A \\
& \overline{\therefore \text{not-}B}
\end{aligned}
$$

## Proposition vs. event language

Two ways of asking the same question!

*"What is the probability that the coin will land heads?"*

**Proposition**: *"the coin will land heads"*

**Question**: What is the probability that this **proposition** is **true**?

A proposition is a sentence that asserts a claim that is either true or false.

Better fit for the logical or bayesian/"subjective" interpretations of probability.

------------------------------------------------------------------------

*"What is the probability of the coin landing heads?"*

**Event**: *"the coin landing heads"*

**Question**: What is the probability that this **event** will **occur**?

An event in not a linguistic entity, it does not assert anything (that is either true or false). An event is a state of affairs in the world that either occurs or doesn't occur.

Better fit for the classical or frequentist/"objective" interpretations of probability.

## Probability as a mathematical object

In mathematics, a function from a set $X$ to a set $Y$ is an assignment of an element $y$ of $Y$ to each element $x$ of $X$.

INPUT: $x$

FUNCTION: $f$

OUTPUT: $y = f(x)$

$f: X \rightarrow Y$

Probability is a function $P$ that assigns a number between 0 and 1 to each subset $A$ of a sample space $\Omega$ (or $S$ or $U$ for "universal set", i.e., the non-empty set of all possible outcomes of a random phenomemon/process/"experiment", e.g., tossing a coin).

$A \subseteq \Omega$, an event/proposition

$P(A)$, the probability of $A$

Given an event space $E$ (i.e., the set of all possible subsets of a sample space $\Omega$), the function $P: E \rightarrow [0, 1]$ must satisfy a number of axioms (Kolmogorov axioms or Cox's theorem):

-   $P(A) \ge 0$
-   $P(\Omega) = 1$
-   $P$ is countably additive: if $A_1, A_2, \ldots, A_n$ are pairwise disjoint sets, then $P(\cup_{i=1}^n A_i) = \sum_{i=1}^n P(A_i)$.

All rules of probability theory are derived from these axioms, for example:

$0 \le P(A) \le 1$

$P(\emptyset) = 0$

Probability theory is the study of probability as a mathematical object.

## Mutually exclusive events

## Independent events

## The rules of probability

negation

disjunction (OR, sum/addition rule)

conjunction (AND, product/multiplication rule)

## Conditional probability

## Inverse probability: Bayes' theorem (or Bayes' rule)

From probability theory to statistical inference

$\text{posterior} = \text{prior} \times \text{likelihood} \div \text{evidence}$

## References

-   Reasoning with Probabilities \[[youtube playlist](https://youtube.com/playlist?list=PL1D85E19690485A3E)\]
-   Introduction to Probability \[[book](http://athenasc.com/probbook.html)\] \[[online course](https://www.edx.org/course/probability-the-science-of-uncertainty-and-data-0)\] \[[youtube playlist](https://youtube.com/playlist?list=PLUl4u3cNGP60hI9ATjSFgLZpbNJ7myAg6)\]
-   Bernoulli's Fallacy \[[book](http://cup.columbia.edu/book/bernoullis-fallacy/9780231199957)\]
