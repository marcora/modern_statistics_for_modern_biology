[
  {
    "objectID": "assignments/index.html",
    "href": "assignments/index.html",
    "title": "Assignments",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "Notes",
    "section": "",
    "text": "Probability theory: The logic of science\n\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2023\n\n\nEdoardo Marcora\n\n\n\n\n\n\n  \n\n\n\n\nStatistical inference\n\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2023\n\n\nEdoardo Marcora\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/statistical_inference.html#interpretations-of-probability",
    "href": "notes/statistical_inference.html#interpretations-of-probability",
    "title": "Statistical inference",
    "section": "Interpretations of probability",
    "text": "Interpretations of probability\nXXX"
  },
  {
    "objectID": "notes/statistical_inference.html#from-probability-theory-to-statistical-inference",
    "href": "notes/statistical_inference.html#from-probability-theory-to-statistical-inference",
    "title": "Statistical inference",
    "section": "From probability theory to statistical inference",
    "text": "From probability theory to statistical inference\n\nModus ponens\n\\[\n\\begin{align}\n& A \\rightarrow B \\\\\n& A \\\\\n& \\overline{\\therefore B}\n\\end{align}\n\\]\n\n\nModus tollens\n\\[\n\\begin{aligned}\n& A \\rightarrow B \\\\\n& \\text{not-}B \\\\\n& \\overline{\\therefore \\text{not-}A}\n\\end{aligned}\n\\]\n\n\nInverse probability: Bayes‚Äô theorem\n\\(P(A \\mid B) = \\frac{P(A) \\times P(B \\mid A)}{P(B)}\\)\n\\(A = H = \\text{hypothesis}\\)\n\\(B = D = \\text{data/observations}\\)\n\\(P(H \\mid D) = \\frac{P(H) \\times P(D \\mid H)}{P(D)}\\)\n\\(\\text{posterior} = \\frac{\\text{prior} \\times \\text{likelihood}}{\\text{evidence}}\\)\n\n\nBernoulli‚Äôs fallacy\na.k.a. fallacy of the transposed conditional; base rate fallacy; prosecutor‚Äôs fallacy\n\\(P(H \\mid D) = \\frac{P(H) \\times P(D \\mid H)}{P(H) \\times P(D \\mid H) + P(\\lnot H) \\times P(D \\mid \\lnot H)}\\)"
  },
  {
    "objectID": "notes/statistical_inference.html#additional-resources",
    "href": "notes/statistical_inference.html#additional-resources",
    "title": "Statistical inference",
    "section": "Additional resources",
    "text": "Additional resources\n\nDeductive and inductive reasoning flow chart [video]\nBasic concepts in logic and argumentation [videos]\nReasoning with probabilities [videos]\nIntroduction to probability [book] [online course] [videos]\nBernoulli‚Äôs fallacy [book]"
  },
  {
    "objectID": "notes/probability_theory.html",
    "href": "notes/probability_theory.html",
    "title": "Probability theory: The logic of science",
    "section": "",
    "text": "Probability is the basis for inductive reasoning (i.e., reasoning with probabilities).\nScientific reasoning is inductive. With a few exceptions (e.g., mathematics and computer programming) nearly all reasoning is inductive.\nUnfortunately, humans suffer from ‚Äúprobability blindness‚Äù and are often incorrect when reasoning with probabilities.\nProbability theory is the study of probability as a mathematical object.\nProbability theory is the foundation of statistical inference (i.e., learning from data under uncertainty), a cornerstone of modern data analysis and scientific research."
  },
  {
    "objectID": "notes/probability_theory.html#why-study-probability",
    "href": "notes/probability_theory.html#why-study-probability",
    "title": "Probability theory: The logic of science",
    "section": "",
    "text": "Probability is the basis for inductive reasoning (i.e., reasoning with probabilities).\nScientific reasoning is inductive. With a few exceptions (e.g., mathematics and computer programming) nearly all reasoning is inductive.\nUnfortunately, humans suffer from ‚Äúprobability blindness‚Äù and are often incorrect when reasoning with probabilities.\nProbability theory is the study of probability as a mathematical object.\nProbability theory is the foundation of statistical inference (i.e., learning from data under uncertainty), a cornerstone of modern data analysis and scientific research."
  },
  {
    "objectID": "notes/probability_theory.html#logic-inductive-vs.-deductive-reasoning",
    "href": "notes/probability_theory.html#logic-inductive-vs.-deductive-reasoning",
    "title": "Probability theory: The logic of science",
    "section": "Logic: Inductive vs.¬†deductive reasoning",
    "text": "Logic: Inductive vs.¬†deductive reasoning\n\nLogic is the study of correct reasoning.\nReasoning is the process of drawing a conclusion/inference from a set of premises.\nReasoning is put into words in the form of an argument.\nAn argument is a set of statements/propositions; more specifically a set of premises and a conclusion.\n\n\\[\n\\begin{align}\n& \\text{premise}_1 \\\\\n& \\text{premise}_2 \\\\\n& \\ldots \\\\\n& \\text{premise}_n \\\\\n& \\overline{\\therefore \\text{conclusion}}\n\\end{align}\n\\]\n\\[\n\\text{IF premise}_1\\ \\text{AND premise}_2 \\ldots \\ \\text{AND premise}_n \\ \\text{THEN conclusion}\n\\]\n\nA statement/proposition is a sentence that asserts a claim that is either true or false based on its correspondence with reality/the state of affairs in the world.\nIn an argument, the premises are the evidence given in support of the conclusion. The conclusion is the statement/proposition that the argument seeks to prove as definitely true (deductive argument) or likely true (inductive argument) if all premises are true.\nIf it is impossible for the premises to all be true and the conclusion still be false, then the argument is deductive.\nIf it is possible for the premises to all be true and the conclusion still be false, then the argument is inductive.\nIn an inductive argument (e.g., an inductive generalization, a causal argument, or reasoning by analogy), the conclusion follows from the premises with likelihood/probability, never with certainty.\nAn inductive argument is defeasable, i.e., subject to revision (conclusion becomes more or less likely/probable) in light of new evidence.\n\n\n\n\n\n\n\nA valid deductive argument guarantees a definitely true conclusion if all premises are true, i.e., in valid deductive argument the premises fully entail the conclusion. When all premises are true and the deductive argument is valid, it is also sound.\nA strong inductive argument guarantees a likely true conclusion if all premises are true, i.e., in a strong inductive argument the premises partially entail the conclusion. When all premises are true and the inductive argument is strong, it is also cogent.\nHow likely is the conclusion given the premises? Probability theory can help us find the answer!\nHow likely does the conclusion need to be before it‚Äôs rational to accept it? Decision theory can help us find the answer!"
  },
  {
    "objectID": "notes/probability_theory.html#logical-operators-and-truth-tables",
    "href": "notes/probability_theory.html#logical-operators-and-truth-tables",
    "title": "Probability theory: The logic of science",
    "section": "Logical operators and truth tables",
    "text": "Logical operators and truth tables\n\nA statement/proposition is simple if it cannot be broken down into other statements/propositions.\nA statement/proposition is composite if it comprises multiple simple or composite statements/propositions connected by logical operators.\nA logical operator is a symbol or word used to connect two or more statements/propositions.\nCommonly used logical operators:\n\n\\(\\text{and} \\quad \\land\\)\n\\(\\text{or} \\quad \\lor\\)\n\\(\\text{not} \\quad \\lnot\\)\n\\(\\text{if-then} \\quad \\rightarrow\\)\n\n\nTruth tables:\n\nXXX"
  },
  {
    "objectID": "notes/probability_theory.html#probability-proposition-vs.-event-language",
    "href": "notes/probability_theory.html#probability-proposition-vs.-event-language",
    "title": "Probability theory: The logic of science",
    "section": "Probability: Proposition vs.¬†event language",
    "text": "Probability: Proposition vs.¬†event language\nWhen using inductive reasoning to answer a probabilistic question, there are two ways of asking the same question:\n\n‚ÄúWhat is the probability that the coin will land heads?‚Äù\n\nProposition: ‚Äúthe coin will land heads‚Äù\nQuestion: What is the probability that this proposition is true?\nA proposition is a claim that is either true or false based on its correspondence with reality/the state of affairs in the world.\nBetter fit for the logical or bayesian/‚Äúsubjective‚Äù interpretations of probability.\n\n‚ÄúWhat is the probability of the coin landing heads?‚Äù\n\nEvent: ‚Äúthe coin landing heads‚Äù\nQuestion: What is the probability that this event will occur?\nAn event is a state of affairs in the world that either occurs or doesn‚Äôt occur.\nBetter fit for the classical or frequentist/‚Äúobjective‚Äù interpretations of probability."
  },
  {
    "objectID": "notes/probability_theory.html#set-theory",
    "href": "notes/probability_theory.html#set-theory",
    "title": "Probability theory: The logic of science",
    "section": "Set theory",
    "text": "Set theory\n\nA set is a collection of objects, typically referred to as elements (or members) of the set.\nThe objects within a set can be anything‚Äînumbers, letters, people, animals, sets, or any other entities‚Äîas long as they are well-defined and distinct, e.g.:\n\n\\(\\{1, 3, 5, 7\\}\\)\nnatural numbers: \\(\\mathbb{N} = \\{1,2,3,\\ldots \\}\\quad \\text{or} \\quad \\{0, 1,2,3,\\ldots \\}\\)\nintegers: \\(\\mathbb{Z} = \\{ \\ldots, -3, -2, -1, 0, 1, 2, 3, \\ldots \\}\\)\nreal numbers: \\(\\mathbb{R}\\)\n\\(\\{ a, b, c, d \\}\\)\n\\(\\{ \\{1, 3, 5, 7 \\} , \\{ a, b, c, d \\} \\}\\)\n\\(\\{ ‚öÄ, ‚öÅ, ‚öÇ, ‚öÉ, ‚öÑ, ‚öÖ \\}\\)\n\\(\\{ ‚öÄ‚öÄ, ‚öÄ‚öÅ, ‚öÄ‚öÇ, ‚öÄ‚öÉ, ‚öÄ‚öÑ, ‚öÄ‚öÖ, ‚öÅ‚öÄ, ‚öÅ‚öÅ, ‚öÅ‚öÇ, ‚öÅ‚öÉ, ‚öÅ‚öÑ, ‚öÅ‚öÖ, ‚öÇ‚öÄ, ‚öÇ‚öÅ, ‚öÇ‚öÇ, ‚öÇ‚öÉ, ‚öÇ‚öÑ, ‚öÇ‚öÖ, \\\\ ‚öÉ‚öÄ, ‚öÉ‚öÅ, ‚öÉ‚öÇ, ‚öÉ‚öÉ, ‚öÉ‚öÑ, ‚öÉ‚öÖ, ‚öÑ‚öÄ, ‚öÑ‚öÅ, ‚öÑ‚öÇ, ‚öÑ‚öÉ, ‚öÑ‚öÑ, ‚öÑ‚öÖ, ‚öÖ‚öÄ, ‚öÖ‚öÅ, ‚öÖ‚öÇ, ‚öÖ‚öÉ, ‚öÖ‚öÑ, ‚öÖ‚öÖ \\}\\)\n\\(\\{ üê±, üê∂, üê∞, üê≠, üêª, üê∑, üê¥, üê§, üêµ, üêü, ü¶ñ, üê∏, ü¶ë, ü¶Ä, üêû, üëΩ, üéÖ \\}\\)\n\\(\\{ üü•, üü©, üü¶, üî¥, üü¢, üîµ \\}\\)\n\nSets can be combined using set operators:\n\n\\(A = \\{ x : x \\in A \\}\\)\n\\(B = \\{ x : x \\in B \\}\\)\nUnion: \\(A \\cup B = \\{ x : x \\in A \\lor x \\in B \\}\\)\nIntersection: \\(A \\cap B = \\{ x : x \\in A \\land x \\in B \\}\\)\nComplement: \\(A^\\complement = \\{ x : x \\notin A \\}\\)"
  },
  {
    "objectID": "notes/probability_theory.html#probability-as-a-mathematical-object",
    "href": "notes/probability_theory.html#probability-as-a-mathematical-object",
    "title": "Probability theory: The logic of science",
    "section": "Probability as a mathematical object",
    "text": "Probability as a mathematical object\nProbability theory is the study of probability as a mathematical object.\nProbability as a function that satisfies the axioms of probability.\nIn mathematics, a function is an assignment of an element \\(y\\) of a set \\(Y\\) to each element \\(x\\) of a set \\(X\\).\nFUNCTION: \\(f: X \\rightarrow Y\\)\nINPUT: \\(x\\)\nOUTPUT: \\(y = f(x)\\)\nA probability model consists of three components: the sample space \\(\\Omega\\), the event space \\(F\\) and the probability measure/distribution \\(P\\).\nThe sample space \\(\\Omega\\) is the set of all possible outcomes of the random phenomenon/stochastic process being modeled.\nThe power set of a set \\(S\\) is the set of all subsets of \\(S\\), including the empty set \\(\\emptyset\\) and \\(S\\) itself.\nThe event space \\(F\\) is the power set of the sample space \\(\\Omega\\).\nAn event \\(A\\) is a subset of the sample space \\(\\Omega\\):\n\\(A \\subseteq \\Omega\\)\nand therefore also an element of the event space \\(F\\):\n\\(A \\in F\\)\nThe probability measure/distribution \\(P\\) is a function from the event space \\(F\\) to the real numbers \\(\\mathbb{R}\\):\n\\(P : F \\rightarrow \\mathbb{R}\\)\n\\(P(A)\\) is the probability of event (or proposition) \\(A\\), i.e., a real number.\nA real number is a number that can be used to measure a continuous one-dimensional quantity such as a length, area, volume, weight and temperature.\n\\(P(A)\\) is a measure of uncertainty, i.e., the likelihood that event \\(A\\) will occur or that proposition \\(A\\) is true."
  },
  {
    "objectID": "notes/probability_theory.html#the-axioms-of-probability",
    "href": "notes/probability_theory.html#the-axioms-of-probability",
    "title": "Probability theory: The logic of science",
    "section": "The axioms of probability",
    "text": "The axioms of probability\nProbability as a function \\(P : F \\rightarrow \\mathbb{R}\\) must satisfy a number of axioms (Kolmogorov axioms; see also Cox‚Äôs theorem for an alternative formulation):\n\n\\(P(A) \\ge 0 \\quad \\forall A \\in F\\)\n\\(P(\\Omega) = 1\\)\n\\(\\text{if} \\quad A_1, A_2, \\ldots, A_n \\ \\text{are disjoint/mutually exclusive events} \\quad \\text{then} \\quad P(\\cup_{i=1}^n A_i) = \\sum_{i=1}^n P(A_i)\\)\n\nAll rules of probability are derived from these axioms, for example:\n\\(0 \\le P(A) \\le 1 \\quad \\forall A \\in F\\)\n\\(P(\\emptyset) = 0\\)\n\\(\\text{if} \\quad A \\subseteq B \\quad \\text{then} \\quad P(A) \\le P(B)\\)"
  },
  {
    "objectID": "notes/probability_theory.html#example-a-single-toin-coss",
    "href": "notes/probability_theory.html#example-a-single-toin-coss",
    "title": "Probability theory: The logic of science",
    "section": "Example: A single toin coss",
    "text": "Example: A single toin coss\nConsider a single coin toss and assume that the coin will either land heads (\\(H\\)) or tails (\\(T\\)) (but not both):\n\\(\\Omega = \\{H, T\\}\\)\n\\(F = \\{ \\emptyset, \\{H\\}, \\{T\\}, \\{H,T\\} \\}\\)\nIf we assume that the coin is fair (i.e., it has equal probability of landing heads or tails):\n\\(P(\\emptyset) = 0\\)\n\\(P(\\{H,T\\}) = P(\\Omega) = 1\\)\n\\(P(\\{H,T\\}) = P(\\{H\\}) + P(\\{T\\}) = 1\\)\n\\(P(\\{H\\}) = P(\\{T\\}) = 0.5\\)"
  },
  {
    "objectID": "notes/probability_theory.html#mutually-exclusivedisjoint-events",
    "href": "notes/probability_theory.html#mutually-exclusivedisjoint-events",
    "title": "Probability theory: The logic of science",
    "section": "Mutually exclusive/disjoint events",
    "text": "Mutually exclusive/disjoint events\n\\(P(A\\ \\text{and}\\ B) = 0\\)"
  },
  {
    "objectID": "notes/probability_theory.html#independent-events",
    "href": "notes/probability_theory.html#independent-events",
    "title": "Probability theory: The logic of science",
    "section": "Independent events",
    "text": "Independent events\n\\(P(A \\mid B) = P(A)\\)"
  },
  {
    "objectID": "notes/probability_theory.html#the-rules-of-probability",
    "href": "notes/probability_theory.html#the-rules-of-probability",
    "title": "Probability theory: The logic of science",
    "section": "The rules of probability",
    "text": "The rules of probability\n\nNegation\n\\(P(\\text{not-}A) = 1 - P(A)\\)\nAlternative notation for \\(P(\\text{not-}A)\\):\n\n\\(P(A')\\)\n\\(P(A^\\complement)\\)\n\\(P(\\overline{A})\\)\n\\(P(\\lnot A)\\)\n\n\n\nDisjunction (sum/addition rule)\n\\(P(A\\ \\text{or}\\ B) = P(A) + P(B) - P(A\\ \\text{and}\\ B)\\)\nAlternative notation for \\(P(A\\ \\text{or}\\ B)\\):\n\n\\(P(A \\cup B)\\)\n\nIf \\(A\\) and \\(B\\) are mutually exclusive/disjoint events: \\(P(A \\cup B) = P(A) + P(B)\\)\nThe disjunction rule is commutative: \\(P(A \\cup B) = P(B \\cup A)\\)\n\n\nConjunction (product/multiplication rule)\n\\(P(A\\ \\text{and} \\ B) = P(A) \\times P(B \\mid A)\\)\nAlternative notation for \\(P(A\\ \\text{and} \\ B)\\):\n\n\\(P(AB)\\)\n\\(P(A,B)\\)\n\\(P(A \\cap B)\\)\n\nIf \\(A\\) and \\(B\\) are independent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nThe conjunction rule is commutative: \\(P(A \\cap B) = P(B \\cap A)\\)"
  },
  {
    "objectID": "notes/probability_theory.html#conditional-probability",
    "href": "notes/probability_theory.html#conditional-probability",
    "title": "Probability theory: The logic of science",
    "section": "Conditional probability",
    "text": "Conditional probability\n\\(P(A \\mid B) = \\frac{P(A\\ \\text{and}\\ B)}{P(B)}\\)\n\\(P(A \\mid B) \\ne P(B \\mid A)\\)"
  },
  {
    "objectID": "notes/probability_theory.html#inverse-probability-bayes-theorem-or-bayes-rule",
    "href": "notes/probability_theory.html#inverse-probability-bayes-theorem-or-bayes-rule",
    "title": "Probability theory: The logic of science",
    "section": "Inverse probability: Bayes‚Äô theorem (or Bayes‚Äô rule)",
    "text": "Inverse probability: Bayes‚Äô theorem (or Bayes‚Äô rule)\n\\(P(A\\ \\text{and} \\ B) = P(A) \\times P(B \\mid A)\\)\n\\(P(B\\ \\text{and} \\ A) = P(B) \\times P(A \\mid B)\\)\n\\(P(A\\ \\text{and}\\ B) = P(B\\ \\text{and}\\ A)\\)\n\\(P(A) \\times P(B \\mid A) = P(B) \\times P(A \\mid B)\\)\n\\(P(A \\mid B) = \\frac{P(A) \\times P(B \\mid A)}{P(B)}\\)"
  },
  {
    "objectID": "notes/probability_theory.html#additional-resources",
    "href": "notes/probability_theory.html#additional-resources",
    "title": "Probability theory: The logic of science",
    "section": "Additional resources",
    "text": "Additional resources\n\nDeductive and inductive reasoning flow chart [video]\nBasic concepts in logic and argumentation [videos]\nReasoning with probabilities [videos]\nIntroduction to probability [book] [online course] [videos]\nBernoulli‚Äôs fallacy [book]"
  },
  {
    "objectID": "exercises/index.html",
    "href": "exercises/index.html",
    "title": "Exercises",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "lectures/index.html",
    "href": "lectures/index.html",
    "title": "Lectures",
    "section": "",
    "text": "No matching items"
  }
]